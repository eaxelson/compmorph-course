{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33d5fc0c",
   "metadata": {},
   "source": [
    "# COMPUTATIONAL MORPHOLOGY WITH HFST TOOLS - LECTURE 1\n",
    "\n",
    "<ul>\n",
    "<li>1. <a href=\"#1.-Prerequisites\">Prerequisites</a></li>\n",
    "<li>2. <a href=\"#2.-Course-material\">Course material</a></li>\n",
    "<li>3. <a href=\"#3.-Course-overview\">Course overview</a></li>\n",
    "<li>4. <a href=\"#4.-Hockett's-models-of-morphology\">Hockett's models of morphology</a></li>\n",
    "<li>5. <a href=\"#5.-Morphological-generators-and-analyzers\">Morphological generators and analyzers</a></li>\n",
    "<li>6. <a href=\"#6.-A-Finite-State-Transducer-that-implements-a-morphological-generator\">A Finite-State Transducer that implements a morphological generator</a></li>\n",
    "<li>7. <a href=\"#7.-Lexc-code-that-represents-this-transducer\">Lexc code that represents this transducer</a></li>\n",
    "<li>8. <a href=\"#8.-Assignments\">Assignments</li>\n",
    "</ul>\n",
    "\n",
    "## HFST - Helsinki Finite-State Technology\n",
    "\n",
    "The HFST toolkit is intended for processing natural language\n",
    "morphologies. The toolkit is demonstrated by wide-coverage\n",
    "implementations of a number of languages of varying morphological\n",
    "complexity. HFST is written mainly in C++, but there is also a Python interface\n",
    "which is demonstrated on these notebooks.\n",
    "\n",
    "## 1. Prerequisites\n",
    "\n",
    "<ul>\n",
    "<li>Foundations of general linguistics</li>\n",
    "<li>Basic knowledge on how to use a computer</li>\n",
    "<li>Some programming experience is desirable</li>\n",
    "<li>Knowledge of Natural Language Processing (NLP) is also a plus</li>\n",
    "</ul>\n",
    "\n",
    "## 2. Course material\n",
    "\n",
    "If you want a book:\n",
    "\n",
    "<ul>\n",
    "<li>Kenneth R. Beesley and Lauri Karttunen: <a href=\"http://press.uchicago.edu/ucp/books/book/distributed/F/bo3613750.html\">Finite State Morphology</a>, CSLI Publications, 2003</li>\n",
    "<li>Daniel Jurafsky and James H. Martin, Speech and Language Processing, Prentice Hall, second edition, 2009</li>\n",
    "</ul>\n",
    "\n",
    "Links:\n",
    "\n",
    "<ul>\n",
    "<li>HFST <a href=\"https://hfst.github.io\">main page</a>.</li>\n",
    "<li>For installation of the HFST package for Python, see our <a href=\"https://pypi.org/project/hfst_dev/\">PyPI pages</a>.</li>\n",
    "<li>For more information about the interface, see our <a href=\"https://github.com/hfst/python-hfst-4.0/wiki\">Github wiki pages</a>.</li>\n",
    "</ul>\n",
    "\n",
    "First, import the package and list its contents with `help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37568edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hfst_dev\n",
    "help(hfst_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863fa11",
   "metadata": {},
   "source": [
    "Then, see for more information on some of the functions, e.g. `compile_lexc_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hfst_dev.compile_lexc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039abd6a",
   "metadata": {},
   "source": [
    "Also print the version number of the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f60a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hfst_dev.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b9aeb",
   "metadata": {},
   "source": [
    "## 3. Course overview\n",
    "\n",
    "This web course is based largely on the course <a href=\"https://courses.helsinki.fi/en/LDA-T3101/120259674\">‚ÄùComputational Morphology‚Äù</a> held at the University of Helsinki spring 2018.\n",
    "The course was taught and planned by Mathias Creutz. Senka Drobac also contributed to the exercises.\n",
    "The web course uses the same examples and exercises, but HFST command line tools have been replaced with HFST Python interface.\n",
    "\n",
    "<table>\n",
    "<tr> <th>Lecture</th> <th>Topics</th> </tr>\n",
    "<tr> <td>1</td> <td>Theories of morphology, generators and analyzers, lexc</td> </tr>\n",
    "<tr> <td>2</td> <td>Finite-state basics, xfst rules</td> </tr>\n",
    "<tr> <td>3</td> <td>Disambiguation, probabilities, finite-state networks summarized</td> </tr>\n",
    "<tr> <td>(4)</td> <td>(Machine learning)</td> </tr>\n",
    "<tr> <td>5</td> <td>Guessers, stemmers, regular expressions in xfst</td> </tr>\n",
    "<tr> <td>6</td> <td>Twolc, two-level rules</td> </tr>\n",
    "<tr> <td>7</td> <td>Flag diacritics, non-concatenative morphology</td> </tr>\n",
    "<tr> <td>8</td> <td>Optimization of finite-state networks</td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ad22a",
   "metadata": {},
   "source": [
    "## 4. Hockett's models of morphology\n",
    "\n",
    "### 4.1. Word and Paradigm (W&P), Example: Finnish nouns\n",
    "\n",
    "<table>\n",
    "<tr> <th>Numbers/Cases</th> <th>Singular</th> <th>Plural</th> </tr>\n",
    "<tr> <th>Nominative</th> <td>susi</td> <td>sudet</td> </tr>\n",
    "<tr> <th>Genitive</th> <td>suden</td> <td>susien, sutten</td> </tr>\n",
    "<tr> <th>Partitive</th> <td>sutta</td> <td>susia</td> </tr>\n",
    "<tr> <th>Inessive</th> <td>sudessa</td> <td>susissa</td> </tr>\n",
    "<tr> <th>Elative</th> <td>sudesta</td> <td>susista</td> </tr>\n",
    "<tr> <th>Illative</th> <td>suteen</td> <td>susiin</td> </tr>\n",
    "<tr> <th>Adessive</th> <td>sudella</td> <td>susilla</td> </tr>\n",
    "<tr> <th>Ablative</th> <td>sudelta</td> <td>susilta</td> </tr>\n",
    "<tr> <th>Allative</th> <td>sudelle</td> <td>susille</td> </tr>\n",
    "<tr> <th>Essive</th> <td>sutena</td> <td>susina</td> </tr>\n",
    "<tr> <th>Translative</th> <td>sudeksi</td> <td>susiksi</td> </tr>\n",
    "<tr> <th>Instructive</th> <td>-</td> <td>susin</td> </tr>\n",
    "<tr> <th>Abessive</th> <td>sudetta</td> <td>susitta</td> </tr>\n",
    "<tr> <th>Comitative</th> <td>-</td> <td>susine(en)</td> </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e04aa2",
   "metadata": {},
   "source": [
    "### 4.2. Item and Arrangement (I&A)\n",
    "\n",
    "#### Morphemes and allomorphs\n",
    "\n",
    "<ul>\n",
    " <li>\"SUSI\": susi, sude-, sute-, sut-, sus-</li>\n",
    " <li>Number:</li>\n",
    "  <ul>\n",
    "   <li>Singular: ‚àÖ (or no morpheme at all: unmarked)</li>\n",
    "   <li>Plural: -t, -i-, -j-</li>\n",
    "  </ul>\n",
    " <li>Case:</li>\n",
    "  <ul>\n",
    "    <li>Genitive: -n, -en, -den, -tten</li>\n",
    "    <li>Partitive: -a, -√§, -ta, -t√§</li>\n",
    "    <li>Etc.</li>\n",
    "  </ul>\n",
    "</ul>\n",
    "\n",
    "#### The allomorphs occur in a specific distribution\n",
    "\n",
    "<ul>\n",
    " <li>E.g., sus- in all plural forms except nominative.</li>\n",
    " <li>No allomorph is more \"basic\" than any other.</li>\n",
    "</ul>\n",
    "\n",
    "### 4.3. Item and Process (I&P)\n",
    "\n",
    "We have roots or bases of morphemes and different processes apply to them.\n",
    "\n",
    "<ul>\n",
    " <li>Nominative: word final 'e' becomes 'i'; 't' in front of 'i' becomes 's' ü°í \"susi\"</li>\n",
    " <li>Genitive: add suffix '+n'; soften 't' to 'd' in closed syllable ü°í \"suden\"</li>\n",
    " <li>Etc.</li>\n",
    "</ul>\n",
    "\n",
    "### 4.4. Corresponding HFST tools\n",
    "\n",
    "<table>\n",
    "<tr> <th>Model/Tool</th> <th><a href=\"https://github.com/hfst/python-hfst-4.0/wiki/PackageHfst#compile_twolc_file-inputfilename-outputfilename-kwargs\">twolc</a></th> <th><a href=\"https://github.com/hfst/python-hfst-4.0/wiki/PackageHfst#compile_lexc_file-filename-kwargs\">lexc</a></th> <th><a href=\"https://github.com/hfst/python-hfst-4.0/wiki/PackageHfst#compile_xfst_file-filename-kwargs\">xfst</a></th> </tr>\n",
    "<tr> <th>Word & Paradigm</th> <td> </td> <td>‚úî</td> <td>‚úî</td> </tr>\n",
    "<tr> <th>Item & Arrangement</th> <td> </td> <td>‚úî</td> <td>‚úî</td> </tr>\n",
    "<tr> <th>Item & Process</th> <td>‚úî</td> <td> </td> <td>‚úî</td> </tr>\n",
    "</table>\n",
    "\n",
    "Check how they work with `help` command.\n",
    "\n",
    "#### twolc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hfst_dev.compile_twolc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f2b1e",
   "metadata": {},
   "source": [
    "#### lexc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hfst_dev.compile_lexc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd5950",
   "metadata": {},
   "source": [
    "#### xfst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hfst_dev.compile_xfst_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebb92a",
   "metadata": {},
   "source": [
    "#### interactive version of xfst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72adafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hfst_dev.start_xfst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2d1247",
   "metadata": {},
   "source": [
    "We will get back to these tools in later sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98c03a",
   "metadata": {},
   "source": [
    "## 5. Morphological generators and analyzers\n",
    "\n",
    "### 5.1. Morphological generator\n",
    "\n",
    "* Input (also called lexical form): `cat+N+Sg+Poss`\n",
    "* Output (also called surface form): `cat's`\n",
    "* The idea is to create a model that generalizes to new word forms.\n",
    "  - Primitive way: List all possible pairs of input and output in the lexeme:\n",
    "    * `cat+N+Sg` ü°í cat\n",
    "    * `cat+N+Pl` ü°í cats\n",
    "    * `cat+N+Sg+Poss` ü°í cat's\n",
    "    * `cat+N+Pl+Poss` ü°í cats'\n",
    "  - More sophisticated way: Model the inner regular morphological structure of words.\n",
    "    * This makes it possible to add a new lemma, such as `dog`, and the model knows how to inflect this word by analogy to the word `cat`.\n",
    "\n",
    "### 5.2. Morphological analyzer\n",
    "\n",
    "* Input (surface form): `cat's`\n",
    "* Output (lexical form): `cat+N+Sg+Poss`\n",
    "* An analyzer produces the opposite mapping compared to the generator:\n",
    "  - The input of the generator is the output of the analyzer.\n",
    "  - The output of the analyzer is the input of the generator.\n",
    "* An analyzer is very useful, for instance:\n",
    "  - when we want to parse natural language text syntactically\n",
    "  - when we want to <i>normalize</i> text, such that we only care about the base form (lemma) of every word in the text; this is used, for instance, in <i>information retrieval</i>.\n",
    "\n",
    "### 5.3. Some simple noun paradigms in English\n",
    "\n",
    "#### Paradigm: N\n",
    "\n",
    "<table>\n",
    "<tr> <td><b>cat</b></td> <td>+Sg (singular)</td> </tr>\n",
    "<tr> <td><b>cat|s</b></td> <td>+Pl (plural)</td> </tr>\n",
    "<tr> <td><b>cat|'s</b></td> <td>+Sg +Poss (singular possessive)</td> </tr>\n",
    "<tr> <td><b>cat|s'</b></td> <td>+Pl +Poss (plural possessive)</td> </tr>\n",
    "</table>\n",
    "\n",
    "<i>Similarly:</i> dog, pet, book, hill, fan\n",
    "\n",
    "#### Paradigm: N_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b9991",
   "metadata": {},
   "source": [
    "(The understroke following the part-of-speech marker N with a subsequent mnemonic 's'\n",
    "is a transparent way of indicating allomorphic inflection types.)\n",
    "\n",
    "<table>\n",
    "<tr> <td><b>kiss</b></td> <td>+Sg (singular)</td> </tr>\n",
    "<tr> <td><b>kiss|es</b></td> <td>+Pl (plural)</td> </tr>\n",
    "<tr> <td><b>kiss|'s</b></td> <td>+Sg +Poss (singular possessive)</td> </tr>\n",
    "<tr> <td><b>kiss|es|'</b></td> <td>+Pl +Poss (plural possessive)</td> </tr>\n",
    "</table>\n",
    "\n",
    "<i>Similarly:</i> wish, mess, church, search, waitress\n",
    "\n",
    "Let's create a morphological generator and analyzer for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb34c8",
   "metadata": {},
   "source": [
    "## 6. A Finite-State Transducer that implements a morphological generator\n",
    "\n",
    "Below is a finite-state transducer (FST) for purely concatenative I&A English noun inflection\n",
    "for our simple example data.\n",
    "The yellow circles represent _states_ and the arrows represent _transitions_ between the states.\n",
    "The state named <i>Root</i> is the initial state and state named <i>\\#</i> the final one.\n",
    "Above each transition, there is the input\n",
    "that the transition <i>consumes</i> and the output that it <i>produces</i>, separated by a colon \":\".\n",
    "The symbol Œµ stands for the <i>epsilon</i>, i.e. the empty symbol. On the input side it means that no symbol is consumed\n",
    "and on the output side that no symbol is produced.\n",
    "The \"Œµ:Œµ\" represents the <i>epsilon transition</i> which is possible without consuming\n",
    "any input or producing any output.\n",
    "We will return to finite-state transducers in more detail in the next part.\n",
    "\n",
    "<img src=\"img/noun_inflection.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a2746",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ## 7. Lexc code that represents this transducer\n",
    "#\n",
    "# ### 7.1 Define all symbols consisting of multiple characters\n",
    "#\n",
    "# ```\n",
    "# Multichar_Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05762c",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "N      ! Noun tag"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a912cb3",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Sg     ! Singular"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aec83b",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Pl     ! Plural"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be832e7",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Poss   ! Possessive form"
   },
   "outputs": [],
   "source": [
    "                ! Another comment that is ignored by the compiler\n",
    "# ```\n",
    "#\n",
    "# Anything between an exclamation mark and the end of a line\n",
    "# is a comment. Comments are ignored by the lexc compiler.\n",
    "# Use comments a lot!\n",
    "# Your code will be clearer to yourself and to others.\n",
    "#\n",
    "# ### 7.2 Define the compulsory Root lexicon\n",
    "#\n",
    "# ```\n",
    "# LEXICON Root\n",
    "#         Nouns ; ! No input, no output\n",
    "# ```\n",
    "#\n",
    "# This is equivalent to writing:\n",
    "#\n",
    "# ```\n",
    "# LEXICON Root\n",
    "# 0:0     Nouns ; ! Explicitly showing no input, no output\n",
    "# ```\n",
    "#\n",
    "# This is further equivalent to writing:\n",
    "#\n",
    "# ```\n",
    "# LEXICON Root\n",
    "# 0       Nouns ; ! When the input and output are identical,\n",
    "                ! you can type only the input side\n",
    "# ```\n",
    "#\n",
    "# <img src=\"img/root_lexicon.png\">\n",
    "#\n",
    "# ### 7.3 Define the Nouns lexicon\n",
    "#\n",
    "# ```\n",
    "# !\n",
    "! NOUNS start here\n",
    "# !\n",
    "#\n",
    "# LEXICON Nouns\n",
    "#\n",
    "cat     N ;\n",
    "# dog     N ;\n",
    "#\n",
    "# church    N_s ;\n",
    "# kiss      N_s ;\n",
    "#\n",
    "# beauty:beaut    N_y ;\n",
    "# sky:sk          N_y ; \n",
    "#\n",
    "# ```\n",
    "# <img src=\"img/nouns_lexicon.png\">\n",
    "#\n",
    "# ### 7.4 Continuation lexicons for the N paradigm\n",
    "#\n",
    "# ```\n",
    "! The noun lexica N and Num are used for stems without\n",
    "! any alternation\n",
    "# \n",
    "# LEXICON N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c72df",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "N:0    Num ;"
   },
   "outputs": [],
   "source": [
    "# \n",
    "# LEXICON Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cca1d",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Sg:0   PossWithS ;"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7da708",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Pl:s   PossWithoutS ;"
   },
   "outputs": [],
   "source": [
    "# ```\n",
    "#\n",
    "# <img src=\"img/n_paradigm.png\">\n",
    "#\n",
    "# ### 7.5 Continuation lexicons for the N_s paradigm\n",
    "#\n",
    "# ```\n",
    "! The noun lexica N_s and Num_s are used for stems that\n",
    "! end in a sibilant and need an extra inserted \"e\"\n",
    "#\n",
    "# LEXICON N_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ce6fc",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "N:0    Num_s ;"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# LEXICON Num_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3b880",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Sg:0   PossWithS ;"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa9f2f",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Pl:es  PossWithoutS ;"
   },
   "outputs": [],
   "source": [
    "# ```\n",
    "#\n",
    "# <img src=\"img/ns_paradigm.png\">\n",
    "#\n",
    "# ### 7.6 Continuation lexicons for the N_y paradigm\n",
    "#\n",
    "# ```\n",
    "! The noun lexica N_y and Num_y are used for stems with\n",
    "# ! \"y\" -> \"ie\" alternation\n",
    "#\n",
    "# LEXICON N_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a2006",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "N:0    Num_y ;"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# LEXICON Num_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff675f",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Sg:y   PossWithS ;"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0f56f",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Pl:ies PossWithoutS ;"
   },
   "outputs": [],
   "source": [
    "# ```\n",
    "#\n",
    "# <img src=\"img/ny_paradigm.png\">\n",
    "#\n",
    "# ### 7.7 Continuation lexicons for possessive marker\n",
    "#\n",
    "# ```\n",
    "! Possessive markers: usually the singular is 's and \n",
    "! the plural is '\n",
    "#\n",
    "# LEXICON PossWithS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cb8d2",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Poss:'s    # ;"
   },
   "outputs": [],
   "source": [
    "#             # ; ! No ending: no input/output \n",
    "# \n",
    "# LEXICON PossWithoutS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d8d3c",
   "metadata": {
    "title": "Poss:'     # ;"
   },
   "outputs": [],
   "source": [
    "#             # ; ! No ending: no input/output\n",
    "#\n",
    "# END\n",
    "# ```\n",
    "# <img src=\"img/poss_ending.png\">\n",
    "#\n",
    "# Note that `END` signifies the end of lexc file. It must be included at the end of each lexc file.\n",
    "#\n",
    "# ### 7.8. Compiling the lexc script into a transducer\n",
    "#\n",
    "# Finally, let's compile the lexc script into a transducer:\n",
    "\n",
    "from hfst_dev import compile_lexc_script\n",
    "\n",
    "generator = compile_lexc_script(\n",
    "\"\"\"\n",
    "Multichar_Symbols\n",
    "        +N      ! Noun tag\n",
    "        +Sg     ! Singular\n",
    "        +Pl     ! Plural\n",
    "        +Poss   ! Possessive form\n",
    "\n",
    "LEXICON Root\n",
    "        Nouns ; ! No input, no output\n",
    "\n",
    "!\n",
    "! NOUNS start here\n",
    "!\n",
    "\n",
    "LEXICON Nouns\n",
    "\n",
    "cat     N ;\n",
    "dog     N ;\n",
    "\n",
    "church    N_s ;\n",
    "kiss      N_s ;\n",
    "\n",
    "beauty:beaut    N_y ;\n",
    "sky:sk          N_y ;\n",
    "\n",
    "\n",
    "! The noun lexica N and Num are used for stems without any alternation\n",
    "\n",
    "LEXICON N\n",
    "+N:0    Num ;\n",
    "\n",
    "LEXICON Num\n",
    "+Sg:0   PossWithS ;\n",
    "+Pl:s   PossWithoutS ;\n",
    "\n",
    "! The noun lexica N_s and Num_s are used for stems that end in a sibilant\n",
    "! and need an extra inserted \"e\"\n",
    "\n",
    "LEXICON N_s\n",
    "+N:0    Num_s ;\n",
    "\n",
    "LEXICON Num_s\n",
    "+Sg:0   PossWithS ;\n",
    "+Pl:es  PossWithoutS ;\n",
    "\n",
    "! The noun lexica N_y and Num_y are used for stems with \"y\" -> \"ie\" alternation\n",
    "\n",
    "LEXICON N_y\n",
    "+N:0    Num_y ;\n",
    "\n",
    "LEXICON Num_y\n",
    "+Sg:y   PossWithS ;\n",
    "+Pl:ies PossWithoutS ;\n",
    "\n",
    "! Possessive markers: usually the singular is 's and the plural is '\n",
    "\n",
    "LEXICON PossWithS\n",
    "+Poss:'s     # ;\n",
    "             # ; ! No ending: no input, no output\n",
    "\n",
    "LEXICON PossWithoutS\n",
    "+Poss:'      # ;\n",
    "             # ; ! No ending: no input, no output\n",
    "\n",
    "END\n",
    "\"\"\", verbosity=2\n",
    ")\n",
    "\n",
    "# We could also write the script to a file and then call `compile_lexc_file`. Note that we set the keyword argument `verbosity` to `2`.\n",
    "# Then we will get more information about the compilation process.\n",
    "# You can test the above command also with `verbosity=1` and `verbosity=0` (or just leaving the argument out).\n",
    "#\n",
    "# Test the transducer:\n",
    "\n",
    "print(generator.lookup('sky+N+Pl'))\n",
    "\n",
    "# and expect the result `(('skies', 0.0),)`, i.e. <i>skies</i> with a zero _weight_. We will return to weights in later lectures.\n",
    "#\n",
    "# Next, <a href=\"https://github.com/hfst/python-hfst-4.0/wiki/HfstTransducer#invert-self\">invert</a> the transducer to get an analyzer (i.e. swap the symbols of input and output side).\n",
    "# After inversion, it is good to <a href=\"https://github.com/hfst/python-hfst-4.0/wiki/HfstTransducer#minimize-self\">minimize</a>\n",
    "# the transducer (i.e. reduce it to an equivalent transducer with the smallest number of states).\n",
    "\n",
    "from hfst_dev import HfstTransducer\n",
    "analyzer = HfstTransducer(generator) # create a copy\n",
    "analyzer.invert()\n",
    "analyzer.minimize()\n",
    "\n",
    "print(analyzer.lookup('skies'))\n",
    "\n",
    "# and expect the result `(('sky+N+Pl', 0.0),)`, i.e. \"the noun <i>sky</i> in plural with a zero weight\".\n",
    "#\n",
    "# Let's check that inverting the analyzer produces a transducer equivalent to the generator with HfstTransducer.compare:\n",
    "\n",
    "analyzer.invert()\n",
    "analyzer.minimize()\n",
    "print(analyzer.compare(generator))\n",
    "\n",
    "\n",
    "# ## 8. Assignments\n",
    "#\n",
    "#\n",
    "# ### Assignment 1.1: Testing a morphological generator\n",
    "#\n",
    "# Compile the lexicon en_ia_morphology_template.lexc into an hfst transducer.\n",
    "# (The file contains the same lexc code that was used in example 7.8.)\n",
    "\n",
    "morph = hfst_dev.compile_lexc_file('en_ia_morphology_template.lexc', verbosity=2)\n",
    "\n",
    "# Optimize the transducer for lookup:\n",
    "\n",
    "morph.lookup_optimize()\n",
    "\n",
    "# Then test it:\n",
    "\n",
    "print(morph.lookup('sky+N+Pl', output='text'))\n",
    "\n",
    "# ... and expect the result: 'skies'.\n",
    "#\n",
    "# Your system works!\n",
    "\n",
    "# For the noun sky, type in all four possible analyses (= lexical forms = input forms), and collect the corresponding surface forms (= output forms) as given by function HfstTransducer.lookup.\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# ### Assignment 1.2: Testing a morphological analyzer\n",
    "#\n",
    "# Invert your transducer, such that input becomes output and vice versa.\n",
    "# Note that a lookup-optimized transducer supports only a couple of functions, so you need to remove optimization with\n",
    "# <a href=\"https://github.com/hfst/python-hfst-4.0/wiki/HfstTransducer#remove_optimization-self\">HfstTransducer.remove_optimization</a> before calling e.g.\n",
    "# <a href=\"https://github.com/hfst/python-hfst-4.0/wiki/HfstTransducer#invert-self\">HfstTransducer.invert</a>.\n",
    "#\n",
    "# This transducer works as an analyzer that retrieves the lexical form of surface forms.\n",
    "# Collect the analyses for the following surface forms: dog's, skies, churches', beauty, cat.\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# ### Assignment 1.3: Adding English nouns to the lexicon\n",
    "#\n",
    "# Add the following missing nouns to the lexc file en_ia_morphology_template.lexc:\n",
    "# book, doggy, fan, hill, mess, pet, search, waitress, wish.\n",
    "#\n",
    "# Go to the browser tab where you chose this lecture (probably the tab on left side)\n",
    "# and click the file en_ia_morphology_template.lexc. A new tab opens where you can edit\n",
    "# the file. After you have added the missing nouns, remember to click File -> Save.\n",
    "# (Tab charaters must be inserted by copying and pasting them.)\n",
    "#\n",
    "# Recompile the transducer using function compile_lexc_file.\n",
    "# Collect the surface forms produced by HfstTransducer.lookup for the lexical forms:\n",
    "# book+N+Sg, doggy+N+Pl, fan+N+Sg+Poss, mess+N+Pl, wish+N+Pl+Poss.\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# Invert the transducer again using HfstTransducer.invert.\n",
    "# Collect the lexical forms produced by HfstTransducer.lookup for the surface forms: books, doggy, pets', waitresses, waitress's, search.\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# ### Assignment 1.4: Adding a new noun paradigm to the lexicon\n",
    "#\n",
    "# Add a new type of nouns to the lexc file, with a specific plural form: criterion - criteria, lexicon - lexica, phenomenon - phenomena.\n",
    "#\n",
    "# Recompile the transducer using compile_lexc_file. Collect the surface forms produced by HfstTransducer.lookup for the lexical forms: criterion+N+Pl, phenomenon+N+Sg+Poss, phenomenon+N+Pl+Poss.\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# For the word \"lexicon\", also allow the parallel regular plural form lexicon - lexicons. Recompile the transducer and collect the surface forms for the lexical forms:\n",
    "# lexicon+N+Sg, lexicon+N+Pl, lexicon+N+Pl+Poss. Do you get duplicate surface forms for some lexical forms? If so, can you explain why?\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# Invert the transducer and collect the lexical forms for the surface forms: lexicons, lexica, criterion's, phenomenon.\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# ### Assignment 1.5: Adding English verb inflection to the lexicon\n",
    "#\n",
    "# Add verb inflection to your lexc file. Include the three paradigms from the table below and all the verbs listed:\n",
    "# jump, look, talk, walk, bake, fake, like, pile, smile, crash, hiss, kiss, miss, search.\n",
    "#\n",
    "# <table>\n",
    "# <tr> <th>Base form</th> <th>Third Person Singular Present</th> <th>Present Participle</th> <th>Past</th> </tr>\n",
    "# <tr> <td>jump</td> <td>jumps</td> <td>jumping</td> <td>jumped</td> </tr>\n",
    "# <tr> <td>bake</td> <td>bakes</td> <td>baking</td> <td>baked</td> </tr>\n",
    "# <tr> <td>crash</td> <td>crashes</td> <td>crashing</td> <td>crashed</td> </tr>\n",
    "# </table>\n",
    "#\n",
    "# Use the tags +V, +Inf,  +Pres3Sg, +Past, +Prog, and remember to declare them as multichar symbols at the top of your lexc file.\n",
    "#\n",
    "# You will need seven new lexicons; you can call them: Verbs, V, V_e, V_s, Tense, Tense_e, Tense_s. (This structure is analogous to the noun lexicons Nouns, N, N_s, N_y, Num, Num_s, Num_y.)\n",
    "#\n",
    "# When you recompile your transducer, you should be able to generate word forms, such as talk+V+Prog -> talking.\n",
    "\n",
    "pass # write your solution here\n",
    "\n",
    "# When you invert your transducer, you should be able to analyze word forms, such as missed -> miss+V+Past.\n",
    "# Collect the analyses for the following surface forms: like, looked, smiling, crashing, searches.\n",
    "\n",
    "pass # write your solution here"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
