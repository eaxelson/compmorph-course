{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTATIONAL MORPHOLOGY WITH HFST TOOLS - LECTURE 5\n",
    "\n",
    "* (1.) Big picture\n",
    "* (2.) Guessers and stemmers\n",
    "* (3.) Pronunciation lexicon for a Language with (almost) regular Orthography: Brazilian Portuguese\n",
    "* (4.) Regular expressions in xfst\n",
    "* (5.) Pronunciation lexicon for a Language with Irregular Orthography: English\n",
    "* (6.) Sound Change in Indo-European languages\n",
    "\n",
    "## 1. Big picture\n",
    "\n",
    "### 1.1. lexc\n",
    "\n",
    "\"Lexicon without any replace rules\"\n",
    "\n",
    "<img src=\"img/big_picture_lexc.png\">\n",
    "\n",
    "### 1.2. xfst and twolc\n",
    "\n",
    "\"Lexicon combined with replace rules\"\n",
    "\n",
    "<img src=\"img/big_picture_xfst_and_twolc.png\">\n",
    "\n",
    "### 1.3. xfst / regular expressions\n",
    "\n",
    "\"Rules without much of a lexicon\" \n",
    "\n",
    "<img src=\"img/big_picture_xfst_and_regexps.png\">\n",
    "\n",
    "## 2. Guessers and stemmers\n",
    "\n",
    "### 2.1. Increased coverage with guessers \n",
    "\n",
    "* Section 9.5.4 in the Beesley & Karttunen book\n",
    "* A finite-state morphological analyzer only recognizes the words that are included in its lexc lexicon.\n",
    "* It may take several person-months (or even years) of work to build up a lexicon with the tens of thousands of stems necessary for broad coverage of real text.\n",
    "* As an alternative, or a complement, one can use\n",
    "  * guessers\n",
    "  * stemmers\n",
    "  * unsupervised morphology\n",
    "\n",
    "### 2.2. Definition of a guesser\n",
    "\n",
    "* A guesser is designed to analyze words that are based on any phonologically possible stem.\n",
    "* The set of phonologically possible stems is definable, more or less precisely, using regular expressions and scripts.\n",
    "* Useful\n",
    "  * as a general backup when normal morphological analysis fails\n",
    "  * for suggesting new stems that need to be added to the lexicon\n",
    "\n",
    "### 2.3. Case study: Esperanto verb guesser lexicon\n",
    "\n",
    "<img src=\"img/esperanto_lexc.png\">\n",
    "\n",
    "### 2.4. Case study: Esperanto verb guesser xfst script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_xfst_script\n",
    "compile_xfst_script(\n",
    "\"\"\"\n",
    "clear stack\n",
    "\n",
    "! We limit ourselves here to lower case letters and ignore some Esperanto letters not found in the\n",
    "! ASCII character set\n",
    "define Vowel     a | e | i | o | u ;\n",
    "define ConsClust b | c | d | f | g | h | j | k | l | m | n | p | r | s | t | v | z |\n",
    "                 k r | p r | t r | g r | b r | d r | s k | s p | s t ;\n",
    "\n",
    "                 ! Each verb root must be of the format Cc V Cc V Cc V Cc ..., where the first consonant cluster Cc is\n",
    "                 ! optional and it must be followed by at least one pair of V Cc ( = vowel + consonant cluster):\n",
    "                 define PossibleVerbRoot  ( ConsClust ) [ [ Vowel ] [ ConsClust ] ]+ \"+Guess\":0 ;\n",
    "\n",
    "                 ! The lexc description is compiled and pushed on the stack\n",
    "                 read lexc esperanto.lexc\n",
    "\n",
    "                 ! Using the 'substitute defined' command, the placeholder symbol is replaced by the value of PossVerbRoot\n",
    "                 substitute defined PossibleVerbRoot for ^GUESSVERBROOT\n",
    "\n",
    "                 ! Make verb vocabulary ready to use\n",
    "                 define AllPossibleVerbs ;\n",
    "                 regex AllPossibleVerbs ;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Case study: Esperanto verb guesser example output\n",
    "\n",
    "Try the following commands by adding them to the end of input that is given to compile_xfst_script:\n",
    "\n",
    "```\n",
    "up donadas     random-upper     random-lower\n",
    "```\n",
    "\n",
    "You should get something like this as a result for up donadas:\n",
    "\n",
    "```\n",
    "don+Guess+Verb+Cont+Pres\n",
    "don+Verb+Cont+Pres\n",
    "donad+Guess+Verb+Pres\n",
    "```\n",
    "\n",
    "for random-upper:\n",
    "\n",
    "```\n",
    "dip+Guess+Verb+Fut\n",
    "egrust+Guess+Verb+Subj\n",
    "fust+Guess+Verb+Fut\n",
    "obr+Guess+Verb+Cont+Fut\n",
    "opop+Guess+Verb+Cond\n",
    "```\n",
    "\n",
    "for random-lower:\n",
    "\n",
    "```\n",
    "etros\n",
    "hemodas\n",
    "jumadis\n",
    "soski\n",
    "tozezus\n",
    "ugrucas\n",
    "vabis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Stemming\n",
    "\n",
    "* A term used particularly in information retrieval to describe the process of reducing inflected (or sometimes derived) words to their word stem, base or root form —generally a written word form.\n",
    "  * The stem is “fish” for “fishing”, “fished”, and “fisher”.\n",
    "  * The stem is “argu” for “argue”, “argued”, “argues”, “arguing”, and “argus”...(!)\n",
    "* The stem does not need to be identical to the morphological root of the word.\n",
    "  * It is sufficient that related words map to the same stem, even if this stem is not in itself a valid root, such as the stem “argu” above, or the stem “citi” for “city” and “cities”.\n",
    "* Algorithms for stemming have been studied in computer science since the 1960s.\n",
    "* Many search engines treat words with the same stem as synonyms, as a kind of query expansion, a process called conflation.\n",
    "\n",
    "#### Porter’s stemmer (1979-1980)\n",
    "\n",
    "* Idea:\n",
    "  * Remove what looks like suffixes of English words\n",
    "  * Tidy up a bit\n",
    "* Feasible for English with such “simple morphology”\n",
    "* The full algorithm is described here: http://tartarus.org/martin/PorterStemmer/def.txt\n",
    "* There are other English stemmers:\n",
    "  * Snowball\n",
    "  * Lancaster\n",
    "  * They are more “aggressive” than the Porter stemmer; they remove more “suffixes”.\n",
    "\n",
    "<img src=\"img/porters_stemmer.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pronunciation lexicon for a Language with (almost) regular Orthography: Brazilian Portuguese\n",
    "\n",
    "### 3.1. Transducing between orthographic and pronounced forms of words\n",
    "\n",
    "* Section 3.5.4 in the Beesley & Karttunen book\n",
    "* Exercise on Portuguese Brazilian\n",
    "* The task is to create a cascade of rules that maps from orthographical strings in Portuguese (this will be the lexical side) down to strings that represent their pronunciation (this will be the surface side).\n",
    "  * There will not be a lexicon.\n",
    "  * A sample mapping of written “caso” to spoken “kazu” looks like this:\n",
    "\n",
    "```\n",
    "Lexical: caso\n",
    "Surface: kazu\n",
    "```\n",
    "\n",
    "### 3.2. Phonetic symbols for Portuguese\n",
    "\n",
    "<img src=\"img/phonetic_symbols_for_portuguese.png\">\n",
    "\n",
    "<i>Table from Beesley & Karttunen (2003).</i>\n",
    "\n",
    "### 3.3. Some example words\n",
    "\n",
    "* What applications that you can think of need a mapping between orthographic and pronounced forms?\n",
    "\n",
    "<img src=\"img/test_data_for_portuguese.png\">\n",
    "\n",
    "<i>Table from Beesley & Karttunen (2003).</i>\n",
    "\n",
    "### 3.4. Conversion from orthography to pronunciation for Brazilian Portuguese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_xfst_script(\n",
    "\"\"\"\n",
    "define Vowel [ a | e | i | o | u\n",
    "             | á | é | í | ó | ú\n",
    "             | â | ê |     ô\n",
    "             | ã |         õ\n",
    "             | à\n",
    "             |                 ü\n",
    "] ;\n",
    "\n",
    "define Rule1 [ s -> z || Vowel _ Vowel ];\n",
    "\n",
    "define Rule2 [ ç -> s ];\n",
    "\n",
    "define Rule3 [ c h -> %$ ];\n",
    "\n",
    "define Rule4 [ c -> s || _ [ e | i | é | í | ê ] ];\n",
    "\n",
    "define Rule5 [ c -> k ];\n",
    "\n",
    "define Rule6 [ s s -> s ];\n",
    "\n",
    "define Rule7 [ n h -> N ];\n",
    "\n",
    "define Rule8 [ l h -> L ];\n",
    "\n",
    "define Rule9 [ h -> 0 ];\n",
    "\n",
    "define Rule10 [ r r -> R ];\n",
    "\n",
    "define Rule11 [ r -> R || .#. _ ];\n",
    "\n",
    "define Rule12 [ e -> i || _ (s) .#. , .#. p _ r ];\n",
    "\n",
    "define Rule13 [ o -> u || _ (s) .#. ];\n",
    "\n",
    "define Rule14 [ d -> J || _ [ i | í ] ];\n",
    "\n",
    "define Rule15 [ t -> C || _ [ i | í ] ];\n",
    "\n",
    "define Rule16 [ z -> s || _ .#. ];\n",
    "\n",
    "read regex Rule1 .o. Rule2 .o. Rule3 .o. Rule4 .o. Rule5 .o. Rule6 .o. Rule7 .o. Rule8 .o.\n",
    "Rule9 .o. Rule10 .o. Rule11 .o. Rule12 .o. Rule13 .o. Rule14 .o. Rule15 .o. Rule16 ;\n",
    "\n",
    "invert net\n",
    "minimize net\n",
    "apply up\n",
    "disse\n",
    "simpático\n",
    "chato\n",
    "braços\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.5. Alternative: Don't define individual rules, but rather one large regular expression\n",
    "\n",
    "<img src=\"img/alternative_for_portuguese.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regular expressions in xfst\n",
    "\n",
    "<i>Figures and tables taken from Beesley & Karttunen (2003).</i>\n",
    "\n",
    "### 4.1. Kleene (1956): Formal language theory\n",
    "\n",
    "<img src=\"img/kleene_formal_language_theory.png\">\n",
    "\n",
    "#### Examples (1)\n",
    "\n",
    "<img src=\"img/kleene_example_1.png\">\n",
    "\n",
    "#### Examples (2)\n",
    "\n",
    "<img src=\"img/kleene_example_2.png\">\n",
    "\n",
    "#### Examples (3)\n",
    "\n",
    "<img src=\"img/kleene_example_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Writing regular expressions in xfst\n",
    "\n",
    "#### Writing regular expressions in xfst (1)\n",
    "\n",
    "```\n",
    "read regex d o g | c a t | h o r s e ;\n",
    "print words\n",
    "```\n",
    "\n",
    "Test by copying the above and giving it as input for interactive xfst program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import start_xfst\n",
    "start_xfst()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also test the examples given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing regular expressions in xfst (2)\n",
    "\n",
    "```\n",
    "read regex [ d o g | c a t | r a t | e l e p h a n t ] - [ d o g | r a t ];\n",
    "print words\n",
    "```\n",
    "\n",
    "#### Writing regular expressions in xfst (3)\n",
    "```\n",
    "read regex (r e)[[m a k e] | [c o m p i l e]]\n",
    "print words\n",
    "```\n",
    "\n",
    "It is a bit like writing a lexicon in xfst without using lexc.\n",
    "\n",
    "#### Writing regular expressions in xfst (4)\n",
    "\n",
    "```\n",
    "read regex a b c* d (e) f+ ;\n",
    "random-words\n",
    "```\n",
    "\n",
    "#### Writing regular expressions in xfst (5)\n",
    "\n",
    "```\n",
    "read regex [ g o:e o:e s e | m o:i u:0 s:c e | b o o k 0:s ] ;\n",
    "upper-words\n",
    "lower-words\n",
    "down mouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Summary: Regular expression syntax in xfst for repetition\n",
    "\n",
    "<img src=\"img/xfst_repetition.png\">\n",
    "\n",
    "#### Syntax for complement (= something else than)\n",
    "\n",
    "<img src=\"img/xfst_complement.png\">\n",
    "\n",
    "#### Writing regular expressions in xfst (6)\n",
    "\n",
    "```\n",
    "read regex [ b o b | j o b | r o b | k n o b ] .o. [ o -> u || \\\\[b | j | n] _ ];\n",
    "upper-words\n",
    "lower-words\n",
    "```\n",
    "\n",
    "#### Syntax for contain/ignore (= is part of)\n",
    "\n",
    "<img src=\"img/xfst_contain_ignore.png\">\n",
    "\n",
    "#### Writing regular expressions in xfst (7)\n",
    "\n",
    "```\n",
    "read regex [[t a l o | k y l ä | k o r i] s s A] .o. [ A -> a || $[a|o|u] ~$[ä|ö|y] _ ] .o. [ A -> ä ] ;\n",
    "upper-words\n",
    "lower-words\n",
    "```\n",
    "\n",
    "#### Writing regular expressions in xfst (8)\n",
    "\n",
    "```\n",
    "read regex [[{talo} | {kylä} | {kori}] {ssA}] .o. [ A -> a || $[a|o|u] ~$[ä|ö|y] _ ] .o. [ A -> ä ] ;\n",
    "upper-words\n",
    "lower-words\n",
    "```\n",
    "\n",
    "You can write a sequence of symbols, such as t a l o, together, if you enclose it in curly brackets: {talo}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_xfst()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pronunciation lexicon for a Language with Irregular Orthography: English\n",
    "\n",
    "<i>Figures taken fron Jurafsky & Martin: Speech and Language Processing, Prentice Hall, 1999.</i>\n",
    "\n",
    "### 5.1. Symbol set for English pronunciation\n",
    "\n",
    "<img src=\"img/english_phonemes.png\">\n",
    "\n",
    "From: Jurafsky & Martin: Speech and Language Processing, Prentice Hall, 1999.\n",
    "\n",
    "### 5.2. \"Two levels times two\"\n",
    "\n",
    "* We do not transduce between the orthographic form and the pronounced form.\n",
    "* We transduce between the morphological lexical form and surface form (as earlier on this course).\n",
    "* Every input and output symbol consists of two parts:\n",
    "*   orthographic form\n",
    "*   pronounced form\n",
    "*   For instance: o|aa\n",
    "\n",
    "<img src=\"img/two_levels_times_two.png\">\n",
    "\n",
    "### 5.3. Example entries from the noun stem lexicon\n",
    "\n",
    "<img src=\"img/example_entries.png\">\n",
    "\n",
    "### 5.4. Transducer for singular and plural inflection\n",
    "\n",
    "<img src=\"img/singular_and_plural_inflection.png\">\n",
    "\n",
    "### 5.5. Noun stems and inflections composed\n",
    "\n",
    "<img src=\"img/noun_stems_and_inflections_composed.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sound Change in Indo-European languages\n",
    "\n",
    "### 6.1. Research initiative\n",
    "\n",
    "* Creation of an interactive lexicon available on the Internet\n",
    "* Using finite-state alternation rules to model sound change from Proto-Indo-European (PIE) to descendant languages\n",
    "* HFST Foma engine (similar to HFST xfst)\n",
    "* People\n",
    "  * Jouna Pyysalo\n",
    "  * Måns Huldén\n",
    "\n",
    "<img src=\"img/pie_lexicon.png\">\n",
    "\n",
    "#### Example 1: Autumn, End\n",
    "\n",
    "<img src=\"img/autumn_end.png\">\n",
    "\n",
    "#### Example 2: Spring, Warmth\n",
    "\n",
    "<img src=\"img/spring_warmth.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information\n",
    "\n",
    "* Selected parts of Chapter 2 and 3 of the Beesley & Karttunen book: “A Systematic Introduction” and “The xfst Interface”"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
