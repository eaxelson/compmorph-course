{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTATIONAL MORPHOLOGY WITH HFST TOOLS - LECTURE 2\n",
    "\n",
    "* (1.) Finite-State Basics\n",
    "* (2.) Set Theory for Finite-State Networks\n",
    "* (3.) Item & Process Morphology Using xfst Rules\n",
    "* (4.) Example: English Adjectives\n",
    "\n",
    "## 1. Finite-State Basics\n",
    "\n",
    "Recall the finite-state transducer (FST) for purely concatenative I&A (Item and Arrangement)\n",
    "English noun inflection from Lecture 1:\n",
    "\n",
    "<img src=\"img/noun_inflection.png\">\n",
    "\n",
    "The yellow circles represent _states_ or _nodes_ and the arrows represent _transitions_\n",
    "or _arcs_ between states. Each transition consumes an input symbol and produces an output symbol.\n",
    "The special symbol Îµ (the epsilon) on the input side means that no symbol is consumed\n",
    "and on the output side that no symbol is produced when following a given transition.\n",
    "\n",
    "A finite-state network that has only input symbols in the transitions is called\n",
    "a finite-state automaton (FSA). It does not produce output, but just recognizes\n",
    "(or rejects) input. Finite-state automaton for a 3-word language:\n",
    "\n",
    "<img src=\"img/three_word_language.png\">\n",
    "\n",
    "* Inputs to the automaton are _symbols_ like: `m, e, c`.\n",
    "* The set of valid symbols that the automaton will accept is its _alphabet_: `{ a, c, e, g, i, m, n, o, r, s, t }`.\n",
    "* The sequences of symbols that the automaton will accept are _words_ like: `canto, mesa`.\n",
    "* The entire set of words that the automaton accepts or recognizes is its _language_: `{ canto, mesa, tigre }`.\n",
    "\n",
    "### Sharing structure in minimal networks:\n",
    "\n",
    "<img src=\"img/fat_father.png\">\n",
    "\n",
    "<img src=\"img/clear_clever_ear_ever.png\">\n",
    "\n",
    "Removing a word from a minimal network may actually increase the size of the network!\n",
    "\n",
    "<img src=\"img/clear_clever_ever.png\">\n",
    "\n",
    "## 2. Set Theory for Finite-State Networks\n",
    "\n",
    "<i>Images from Beesley & Karttunen (2003): Finite State Morphology.</i>\n",
    "\n",
    "### Examples of sets:\n",
    "\n",
    "<img src=\"img/two_sets.png\">\n",
    "\n",
    "<img src=\"img/empty_set.png\">\n",
    "\n",
    "### Some sets viewed as networks:\n",
    "\n",
    "<img src=\"img/empty_network.png\">\n",
    "\n",
    "<img src=\"img/empty_string_network.png\">\n",
    "\n",
    "### Some infinite sets:\n",
    "\n",
    "<img src=\"img/zero_or_more_a.png\">\n",
    "\n",
    "<img src=\"img/universal_language.png\">\n",
    "\n",
    "### Relations:\n",
    "\n",
    "<img src=\"img/lowercase2uppercase.png\">\n",
    "\n",
    "The example above shows an infinite relation containing pairs, such as\n",
    "`{<\"dog\",\"DOG\">,<\"cat\",\"CAT\">,<\"mouse\",\"MOUSE\">,...}`\n",
    "\n",
    "We can also have relations between lexical forms and surface forms, such as:\n",
    "```\n",
    "{<\"cantar+Verb+PresInd+1P+Sg\", \"canto\">,\n",
    " <\"cantar+Verb+PresInd+1P+Pl\",\"cantamos\">,\n",
    " <\"canto+Noun+Masc+Sg\",\"canto\">, ...}\n",
    "\n",
    "```\n",
    "\n",
    "### Union of sets\n",
    "\n",
    "<img src=\"img/union_of_sets.png\">\n",
    "\n",
    "For instance, the union of the sets `{\"clear\", \"clever\", \"ear\", \"ever\"}` and `{\"fat\", \"father\"}` is\n",
    "`{\"clear\", \"clever\", \"ear\", \"ever\", \"fat\", \"father\"}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import fst, disjunct\n",
    "set1 = fst(('clear','clever','ear','ever'))\n",
    "set2 = fst(('fat','father'))\n",
    "union_set = disjunct((set1, set2))\n",
    "print(union_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The union shown as a network:\n",
    "\n",
    "<img src=\"img/union_of_sets_as_network.png\">\n",
    "\n",
    "### Intersection of sets\n",
    "\n",
    "<img src=\"img/intersection_of_sets.png\">\n",
    "\n",
    "For instance, the intersection of sets `{\"clear\", \"clever\", \"ear\"}` and `{\"ear\", \"ever\"}` is `{\"ear\"}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import intersect\n",
    "set1 = fst(('clear','clever','ear'))\n",
    "set2 = fst(('ear','ever'))\n",
    "intersection_set = intersect((set1, set2))\n",
    "print(intersection_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtraction of one set from another\n",
    "\n",
    "<img src=\"img/subtraction_of_sets.png\">\n",
    "\n",
    "For instance, the subtraction of sets `{\"clear\", \"clever\", \"ear\"}` and `{\"clever\", \"ear\"}` is `{\"clear\"}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import subtract\n",
    "set1 = fst(('clear','clever','ear'))\n",
    "set2 = fst(('clever','ear'))\n",
    "subtraction_set = subtract((set1, set2))\n",
    "print(subtraction_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation of sets\n",
    "\n",
    "<img src=\"img/concatenation_of_sets.png\">\n",
    "\n",
    "The concatenation is `{\"works\", \"working\", \"worked\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import concatenate\n",
    "set1 = fst(('work'))\n",
    "set2 = fst(('s','ing','ed'))\n",
    "concatenation_set = concatenate((set1, set2))\n",
    "print(concatenation_set.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition of transducers\n",
    "\n",
    "<img src=\"img/composition.png\">\n",
    "\n",
    "The composition is `{<\"cat\",\"Katze\">}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compose\n",
    "set1 = fst({'cat':'chat'})\n",
    "set2 = fst({'chat':'Katze'})\n",
    "composition_set = compose((set1, set2))\n",
    "print(composition_set.extract_paths()) # TODO: @_EPSILON_SYMBOL_@ is printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection\n",
    "\n",
    "* Projection is extracting one side of a relation.\n",
    "* The upper/input projection of `<\"cat\", \"CHAT\">` is \"cat\".\n",
    "* The lower/output projection of `<\"cat\", \"CHAT\">` is \"CHAT\".\n",
    "\n",
    "<img src=\"img/projection.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = fst({'cat':'CHAT'})\n",
    "cat.input_project()\n",
    "cat.minimize() # get rid of epsilons\n",
    "print(cat.extract_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "CHAT = fst({'cat':'CHAT'})\n",
    "CHAT.output_project()\n",
    "CHAT.minimize() # get rid of epsilons\n",
    "print(CHAT.extract_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set operations expressed in the xfst language\n",
    "\n",
    "```\n",
    "[ A | B ] denotes the union of the two languages or relations A and B (\"or\"-operation).\n",
    "[ A & B ] denotes the intersection (\"and\"-operation).\n",
    "[ A - B ] denotes the subtraction of B from A.\n",
    "[ A B ] denotes the concatenation.\n",
    "[ A .o. B ] denotes the composition of the relations.\n",
    "A.u denotes the upper (i.e. input) projection.\n",
    "A.l denotes the lower (o.e. output) projection.\n",
    "```\n",
    "\n",
    "## 3. Item & Process morphology using xfst rules\n",
    "\n",
    "Recall the finite-state transducer for purely concatenative I&A English\n",
    "noun inflection (from previous lecture):\n",
    "\n",
    "<img src=\"img/noun_inflection.png\">\n",
    "\n",
    "A more compact finite-state transducer for I&P English noun inflection:\n",
    "\n",
    "<img src=\"img/noun_inflection_compact.png\">\n",
    "\n",
    "### Cascade of transducers: Rule 1\n",
    "\n",
    "Insert 'e' after the end of the stem in front of 's', if the stem ends in\n",
    "'s', 'x', 'ch', 'sh' or 'y'.\n",
    "\n",
    "Expressed as an xfst rule:\n",
    "\n",
    "`define InsertE   [. .] -> e || [ s | x | c h | s h | y ] %^ _ s ;`\n",
    "\n",
    "<img src=\"img/InsertE.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import regex, HfstTransducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertE = regex(\"[. .] -> e || [ s | x | c h | s h | y ] %^ _ s\")\n",
    "print(InsertE.lookup(\"sky^s'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascade of transducers: Rule 2\n",
    "\n",
    "Rewrite 'y' as 'i' when followed by the end of the stem, which is\n",
    "further followed by 'e'.\n",
    "\n",
    "Expressed as an xfst rule:\n",
    "\n",
    "`define YToI    y -> i || _ %^ e ;`\n",
    "\n",
    "<img src=\"img/YToI.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YToI = regex(\"y -> i || _ %^ e\")\n",
    "print(YToI.lookup(\"sky^es'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cascade of transducers: Rule 3\n",
    "\n",
    "Remove the end of stem marker\n",
    "\n",
    "Expressed as an xfst rule:\n",
    "\n",
    "`define CleanUp    %^ -> 0 ;`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanUp = regex(\"%^ -> 0\")\n",
    "print(CleanUp.lookup(\"ski^es'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/CleanUp.png\">\n",
    "\n",
    "### Cascade equivalent to single FST\n",
    "\n",
    "<img src=\"img/cascade.png\">\n",
    "\n",
    "<i>Image from Beesley & Karttunen (2003): Finite State Morphology.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_lexc_file\n",
    "lexicon = compile_lexc_file('en_ia_morphology.lexc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compose\n",
    "cascade = compose((lexicon, InsertE, YToI, CleanUp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When our lexicon is composed with our rules, we can actually produce one\n",
    "single FST and 'jump' from the lexical-form input straight to the final\n",
    "output in one go, without producing the intermediate steps.\n",
    "\n",
    "```\n",
    "Example input:  sky+N+Pl+Poss\n",
    "Lexicon output: sky^s'\n",
    "Rule 1 output:  sky^es\n",
    "Rule 2 output:  ski^es\n",
    "Rule 3 output:  skies\n",
    "```\n",
    "\n",
    "The single FST will give directly: sky+N+Pl+Poss ðŸ¡’ skies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cascade.lookup(\"sky+N+Pl+Poss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The order of the rules matters!\n",
    "\n",
    "What would happen if we reordered the rules (below) used in our simple\n",
    "English noun morphology?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = compose((lexicon,YToI, InsertE, CleanUp))\n",
    "print(cascade.lookup(\"sky+N+Pl+Poss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xfst notation explained in context\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_1.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_2.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_3.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_4.png\">\n",
    "\n",
    "<img src=\"img/xfst_notation_explained_5.png\">\n",
    "\n",
    "<i>Images from Beesley & Karttunen (2003): Finite State Morphology.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: English adjectives\n",
    "\n",
    "### Lexicon (lexc) of some English adjectives\n",
    "\n",
    "The file `en_ip_adjectives_lexicon.lexc`\n",
    "\n",
    "```\n",
    "Multichar_Symbols\n",
    "+A       ! Adjective tag\n",
    "+Pos     ! Positive\n",
    "+Cmp     ! Comparative\n",
    "+Sup     ! Superlative\n",
    "\n",
    "LEXICON Root\n",
    "Adjectives ;\n",
    "\n",
    "LEXICON Adjectives\n",
    "big     A ;\n",
    "cool    A ;\n",
    "crazy   A ;\n",
    "great   A ;\n",
    "grim    A ;\n",
    "happy   A ;\n",
    "hot     A ;\n",
    "long    A ;\n",
    "quick   A ;\n",
    "sad     A ;\n",
    "short   A ;\n",
    "slow    A ;\n",
    "small   A ;\n",
    "warm    A ;\n",
    "\n",
    "LEXICON A\n",
    "+A:^    Comparison ;\n",
    "\n",
    "LEXICON Comparison\n",
    "+Pos:0  # ;\n",
    "+Cmp:er # ;\n",
    "+Sup:est  # ;\n",
    "\n",
    "END \n",
    "```\n",
    "\n",
    "### Suggested xfst script for English adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_xfst_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_lexicon = compile_xfst_script(\"\"\"\n",
    "! Read lexicon and make a regex of it\n",
    "read lexc en_ip_adjectives_lexicon.lexc\n",
    "define Lexicon ;\n",
    "regex Lexicon ;\n",
    "\n",
    "! y/i alternation\n",
    "define YToI     y -> i || _ %^ e ;\n",
    "\n",
    "! Last rule cleans away the boundary marker\n",
    "define CleanUp  %^ -> 0 ;\n",
    "\n",
    "! Compose lexicon with rules\n",
    "regex Lexicon .o. YToI .o. CleanUp ;\n",
    "\n",
    "! Output all surface forms of the words\n",
    "lower-words \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are issues with some word forms...\n",
    "\n",
    "```\n",
    "big         biger       bigest\n",
    "cool        cooler      coolest\n",
    "crazy       crazier     craziest\n",
    "great       greater     greatest\n",
    "grim        grimer      grimest\n",
    "happy       happier     happiest\n",
    "hot         hoter       hotest\n",
    "long        longer      longest\n",
    "quick       quicker     quickest\n",
    "sad         sader       sadest\n",
    "short       shorter     shortest\n",
    "slow        slower      slowest\n",
    "small       smaller     smallest\n",
    "warm        warmer      warmest\n",
    "```\n",
    "\n",
    "### Corrected xfst script for English adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_lexicon = compile_xfst_script(\"\"\"\n",
    "! Read lexicon and make a regex of it\n",
    "read lexc en_ip_adjectives_lexicon.lexc\n",
    "define Lexicon ;\n",
    "regex Lexicon ;\n",
    "\n",
    "define Vowel [ a | e | i | o | u | y ] ;\n",
    "define Cons  [ b | c | d | f | g | h | j | k | l | m |\n",
    "n | p | q | r | s | t | v | w | x | z ] ;\n",
    "\n",
    "! y/i alternation\n",
    "define YToI     y -> i || _ %^ e ;\n",
    "\n",
    "! Consonant reduplication\n",
    "define DoubleCons d -> d d ,\n",
    "g -> g g ,\n",
    "m -> m m ,\n",
    "t -> t t || Cons Vowel _ %^ e ;\n",
    "\n",
    "! Last rule cleans away the boundary marker\n",
    "define CleanUp  %^ -> 0 ;\n",
    "\n",
    "! Compose lexicon with rules\n",
    "regex Lexicon .o. YToI .o. DoubleCons .o. CleanUp ;\n",
    "\n",
    "! Output all surface forms of the words\n",
    "lower-words \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it works!\n",
    "\n",
    "```\n",
    "big        bigger      biggest\n",
    "cool       cooler      coolest\n",
    "crazy      crazier     craziest\n",
    "great      greater     greatest\n",
    "grim       grimmer     grimmest\n",
    "happy      happier     happiest\n",
    "hot        hotter      hottest\n",
    "long       longer      longest\n",
    "quick      quicker     quickest\n",
    "sad        sadder      saddest\n",
    "short      shorter     shortest\n",
    "slow       slower      slowest\n",
    "small      smaller     smallest\n",
    "warm       warmer      warmest\n",
    "```\n",
    "\n",
    "More information\n",
    "\n",
    "* Chapter 1 of the Beesley & Karttunen book: \"A Gentle Introduction\"\n",
    "* Chapter 3 of the Beesley & Karttunen book: \"The xfst Interface\"\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
